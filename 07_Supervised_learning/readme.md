Это проект по теме "Обучение с учителем". Нас просят построить модель, предсказывающую, уйдет ли клиент банка в ближайшем будущем. Вероятно, один из самых важных проектов за все время учебы. В нем рассмотрено и реализовано много очень базовых МЛ-понятий. Рассмотрены стандартные модели библиотеки sklearn Decision Tree, Random Forest, Logistic Regression. Рассмотрена концепция подбора гиперпараметров модели для улучшения результатов. Рассмотрены метрики precision, recall, f1, AUC ROC, построены PR и ROC кривые. В проекте рассматривается проблема дисбаланса классов при классификации и попытки этот дисбаланс побороть: даунсемплинг, апсемплинг и взвешивание. Поскольку на момент выполнения задания я не знал о таких вещах, как Pipeline, GridSearch, Cross validation и тем более об optuna, перебор параметров осуществлялся в самописных функциях, которые могут не очень хорошо выглядеть, но зато делают, то, что должны.

This is a project on the topic "Supervised learning'. We are asked to build a model that predicts whether a bank customer will churn in the near future. Probably one of the most important projects of all the time of study. It discusses and implements many very basic ML concepts. The standard models of the sklearn library Decision Tree, Random Forest, Logistic Regression are considered. The concept of selecting model hyperparameters to improve the results is considered. Precision, recall, f1, AUC ROC metrics are considered, PR and ROC curves are constructed. The problem of class imbalance is discussed and attempts to overcome it are made: downsampling, upsampling and weighting. Since at the time of the project completion I did not know about such things as Pipeline, GridSearch, Cross validation, and even more so about optuna, the enumeration of parameters was carried out in self-written functions that may not look very good, but they do what they should.
